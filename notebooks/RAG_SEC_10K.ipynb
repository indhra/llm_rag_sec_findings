{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f09af7f7",
      "metadata": {
        "id": "f09af7f7"
      },
      "source": [
        "# SEC 10-K RAG System - Colab Demo\n",
        "\n",
        "**Author:** Indhra  \n",
        "**Assignment:** LLM + RAG Hands-On Coding Test\n",
        "\n",
        "This notebook demonstrates a RAG system for answering questions from Apple 2024 and Tesla 2023 10-K SEC filings.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/indhra/llm_rag_sec_findings/blob/main/notebooks/RAG_SEC_10K.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa74e5ee",
      "metadata": {
        "id": "fa74e5ee"
      },
      "source": [
        "## 1. Setup\n",
        "\n",
        "Clone the repository and install dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "75c1d526",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75c1d526",
        "outputId": "131d41df-4116-4666-b187-ca8f43ab9474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'llm_rag_sec_findings'...\n",
            "remote: Enumerating objects: 157, done.\u001b[K\n",
            "remote: Counting objects: 100% (157/157), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 157 (delta 72), reused 138 (delta 56), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (157/157), 1.72 MiB | 5.89 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n",
            "/Users/indhra/Machine_learning/Resumes_Indhra/ABB_JAN26/notebooks/llm_rag_sec_findings\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/indhra/llm_rag_sec_findings.git\n",
        "%cd llm_rag_sec_findings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "21765355",
      "metadata": {
        "id": "21765355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: pip\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -q pymupdf tiktoken sentence-transformers faiss-cpu rank-bm25 groq python-dotenv tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "eb06aced",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eb06aced",
        "outputId": "17d442ae-f662-4bf9-bb28-c6cbd867e552"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'https://console.groq.com/keys'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"https://console.groq.com/keys\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a629a85a",
      "metadata": {
        "id": "a629a85a"
      },
      "outputs": [],
      "source": [
        "# Set your Groq API key (free at console.groq.com)\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Option 1: Enter manually (strips whitespace to prevent errors)\n",
        "api_key = getpass(\"Enter your Groq API key: \")\n",
        "os.environ[\"GROQ_API_KEY\"] = api_key.strip()\n",
        "\n",
        "# Option 2: Use Colab secrets (recommended)\n",
        "# from google.colab import userdata\n",
        "# os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY').strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f497f73c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f497f73c",
        "outputId": "1e4dcec5-536b-4a68-b058-27a84323e216"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”‘ Validating Groq API key...\n",
            "âœ… API key is valid and working!\n",
            "   Model: llama-3.1-8b-instant\n",
            "   Response: It's nice to meet\n"
          ]
        }
      ],
      "source": [
        "# Validate Groq API key\n",
        "print(\"ğŸ”‘ Validating Groq API key...\")\n",
        "try:\n",
        "    from groq import Groq\n",
        "\n",
        "    # Ensure the API key is stripped of any leading/trailing whitespace or newlines\n",
        "    groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "    if groq_api_key:\n",
        "        client = Groq(api_key=groq_api_key.strip())\n",
        "    else:\n",
        "        raise ValueError(\"GROQ_API_KEY environment variable is not set.\")\n",
        "\n",
        "    # Test with a simple request\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Hi\"}],\n",
        "        max_tokens=5\n",
        "    )\n",
        "\n",
        "    print(\"âœ… API key is valid and working!\")\n",
        "    print(f\"   Model: {response.model}\")\n",
        "    print(f\"   Response: {response.choices[0].message.content}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ API key validation failed: {str(e)}\")\n",
        "    print(\"\\nPlease check your API key and try again.\")\n",
        "    print(\"Get a free key at: https://console.groq.com/keys\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30cc5b1b",
      "metadata": {
        "id": "30cc5b1b"
      },
      "source": [
        "## 2. Download SEC 10-K PDFs\n",
        "\n",
        "Download Apple 2024 and Tesla 2023 10-K filings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "91e1196a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91e1196a",
        "outputId": "904f96b9-1e9f-4015-b99e-9493ff6faf71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using local copy\n",
            "Using local copy\n",
            "total 3816\n",
            "drwxr-xr-x@  4 indhra  staff     128 Jan 30 20:07 \u001b[34m.\u001b[m\u001b[m\n",
            "drwxr-xr-x@ 16 indhra  staff     512 Jan 30 20:07 \u001b[34m..\u001b[m\u001b[m\n",
            "-rw-r--r--@  1 indhra  staff  963934 Jan 30 20:07 10-Q4-2024-As-Filed.pdf\n",
            "-rw-r--r--@  1 indhra  staff  984581 Jan 30 20:07 tsla-20231231-gen.pdf\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# Download Apple 10-K 2024\n",
        "!wget -q -O data/apple_10k_2024.pdf \"https://www.sec.gov/Archives/edgar/data/320193/000032019324000123/aapl-20240928.htm\" 2>/dev/null || echo \"Using local copy\"\n",
        "\n",
        "# Download Tesla 10-K 2023\n",
        "!wget -q -O data/tesla_10k_2023.pdf \"https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm\" 2>/dev/null || echo \"Using local copy\"\n",
        "\n",
        "# Check if files exist\n",
        "!ls -la data/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99bf36ca",
      "metadata": {
        "id": "99bf36ca"
      },
      "source": [
        "## 3. Initialize RAG Pipeline\n",
        "\n",
        "Load the embedding model, reranker, and LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0bc89bc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bc89bc1",
        "outputId": "6da7e4fd-221e-40a4-e3b5-b2918d15eaab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Initializing SEC 10-K RAG Pipeline\n",
            "============================================================\n",
            "\n",
            "[1/4] Loading embedding model...\n",
            "Using embedding model: bge-small\n",
            "  Model: BAAI/bge-small-en-v1.5\n",
            "  Dimensions: 384\n",
            "  Quality: good, Speed: fast\n",
            "  Device: mps\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16b7378294674e909f9a23db73ecc44d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BertModel LOAD REPORT from: BAAI/bge-small-en-v1.5\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Model loaded successfully\n",
            "\n",
            "[2/4] Loading reranker...\n",
            "Using reranker: ms-marco-mini\n",
            "  Model: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "  Quality: good, Speed: fast\n",
            "  Device: mps\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20a41da8dbcb4e5b91f9f14e66146ae8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "Key                          | Status     |  | \n",
            "-----------------------------+------------+--+-\n",
            "bert.embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Reranker loaded\n",
            "\n",
            "[3/4] Initializing LLM...\n",
            "GroqLLM initialized with model: llama-3.1-8b-instant\n",
            "\n",
            "[4/4] Pipeline ready!\n",
            "  Hybrid search: True\n",
            "  Retrieval top-k: 15\n",
            "  Rerank top-k: 7\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "from src.pipeline import RAGPipeline\n",
        "\n",
        "# Initialize with Groq (free tier)\n",
        "pipeline = RAGPipeline(\n",
        "    embedding_model=\"bge-small\",    # Fast, good quality\n",
        "    reranker_model=\"ms-marco-mini\", # Fast cross-encoder\n",
        "    llm_provider=\"groq\",            # Free API\n",
        "    use_hybrid_search=True,         # Vector + BM25\n",
        "    top_k_retrieval=15,             # Initial candidates (increased for better coverage)\n",
        "    top_k_rerank=7                  # After reranking (increased for complex questions)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd0a14cb",
      "metadata": {
        "id": "fd0a14cb"
      },
      "source": [
        "## 4. Index Documents\n",
        "\n",
        "Parse PDFs, chunk, embed, and build the vector index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e0f30e1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0f30e1a",
        "outputId": "7a28681d-d15d-4dde-9760-fa7c5d043741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Indexing SEC 10-K Documents\n",
            "============================================================\n",
            "\n",
            "[Step 1] Parsing PDFs...\n",
            "Parsing 'Apple 10-K' (121 pages)...\n",
            "âœ“ Parsed 121 pages from Apple 10-K\n",
            "Parsing 'Tesla 10-K' (130 pages)...\n",
            "âœ“ Parsed 130 pages from Tesla 10-K\n",
            "\n",
            "[Step 2] Chunking documents...\n",
            "Chunking Apple 10-K...\n",
            "  â†’ Created 239 chunks\n",
            "Chunking Tesla 10-K...\n",
            "  â†’ Created 252 chunks\n",
            "\n",
            "âœ“ Total chunks: 491\n",
            "  Average tokens per chunk: 376\n",
            "  Min/Max tokens: 11/1050\n",
            "\n",
            "[Step 3] Generating embeddings...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "507b4689192a43d3a29c436fa0174289",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 4] Building vector index...\n",
            "VectorStore initialized\n",
            "  Dimension: 384\n",
            "  Hybrid search: True\n",
            "  Hybrid alpha: 0.7 (vector weight)\n",
            "Adding 491 chunks to vector store...\n",
            "Building BM25 index...\n",
            "  BM25 index built with 491 documents\n",
            "âœ“ Vector store now contains 491 vectors\n",
            "\n",
            "[Step 5] Saving index to outputs/index...\n",
            "Saving vector store to outputs/index...\n",
            "âœ“ Vector store saved (491 chunks)\n",
            "\n",
            "============================================================\n",
            "âœ“ Indexing complete! 491 chunks indexed\n",
            "============================================================\n",
            "\n",
            "âœ… Indexed 491 chunks!\n"
          ]
        }
      ],
      "source": [
        "# This takes ~2 minutes on Colab (mostly embedding generation)\n",
        "num_chunks = pipeline.index_documents(data_dir=\"data/\")\n",
        "print(f\"\\nâœ… Indexed {num_chunks} chunks!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fd07191",
      "metadata": {
        "id": "8fd07191"
      },
      "source": [
        "## 5. Ask Questions!\n",
        "\n",
        "Now we can ask questions about the 10-K filings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "83915419",
      "metadata": {
        "id": "83915419"
      },
      "outputs": [],
      "source": [
        "def ask(question: str):\n",
        "    \"\"\"Helper function to ask a question and display the answer.\"\"\"\n",
        "    print(f\"â“ {question}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    result = pipeline.answer_question(question)\n",
        "\n",
        "    print(f\"ğŸ’¡ {result['answer']}\")\n",
        "    print(f\"\\nğŸ“š Sources: {result['sources']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "81bd95c0",
      "metadata": {
        "id": "81bd95c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â“ What was Apple's total revenue for fiscal year 2024?\n",
            "------------------------------------------------------------\n",
            "ğŸ’¡ ## Understand\n",
            "The question is asking for Apple's total revenue for fiscal year 2024.\n",
            "\n",
            "## Locate\n",
            "The relevant information is found in context id=\"6\" source=\"\n",
            "\n",
            "ğŸ“š Sources: ['Apple 10-K', 'Item 8', 'p. 32']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test: Apple revenue\n",
        "ask(\"What was Apple's total revenue for fiscal year 2024?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "671dfe40",
      "metadata": {
        "id": "671dfe40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â“ What was Tesla's net income for fiscal year 2023?\n",
            "------------------------------------------------------------\n",
            "ğŸ’¡ ## Understand\n",
            "The question is asking for Tesla's net income for fiscal year 2023.\n",
            "\n",
            "## Locate\n",
            "The relevant information is found in context id=\"4\"\n",
            "\n",
            "ğŸ“š Sources: ['Tesla 10-K', 'Item 8', 'p. 51', 'Tesla 10-K', 'Item 8', 'p. 51']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test: Tesla net income\n",
        "ask(\"What was Tesla's net income for fiscal year 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fdb3f052",
      "metadata": {
        "id": "fdb3f052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â“ How much did Apple spend on research and development in 2024?\n",
            "------------------------------------------------------------\n",
            "ğŸ’¡ ## Understand\n",
            "The question is asking for the amount Apple spent on research and development in 2024.\n",
            "\n",
            "## Locate\n",
            "The relevant information is found in context chunk \"1\" and context chunk \"2\".\n",
            "\n",
            "## Extract\n",
            "From context chunk \"1\", we have:\n",
            "\"Research and development\n",
            "$\n",
            "31,370\n",
            "5 % $\n",
            "29,915\n",
            "14 % $\n",
            "26,251\n",
            "Percentage of total net sales\n",
            "8%\n",
            "8%\n",
            "7%\"\n",
            "\n",
            "From context chunk \"2\", we have:\n",
            "\"Research and development\n",
            "$\n",
            "31,370\n",
            "\"\n",
            "\n",
            "## Calculate\n",
            "The amount spent on research and development in 2024 is already provided in the context.\n",
            "\n",
            "## Synthesize\n",
            "Apple spent $31,370 million on research and development in 2024.\n",
            "\n",
            "## Cite\n",
            "\n",
            "ğŸ“š Sources: ['Apple 10-K', 'Item 7', 'p. 27', 'Apple 10-K', 'Item 8', 'p. 32']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test: Apple R&D\n",
        "ask(\"How much did Apple spend on research and development in 2024?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "41f2876d",
      "metadata": {
        "id": "41f2876d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â“ How much cash and cash equivalents did Tesla report?\n",
            "------------------------------------------------------------\n",
            "ğŸ’¡ ## Understand\n",
            "The question is asking for the amount of cash and cash equivalents reported by Tesla.\n",
            "\n",
            "## Locate\n",
            "The relevant context chunks are:\n",
            "- <context id=\"1\" source=\"[Tesla 10-K, Item 8, p. 50]\"> (Consolidated Balance Sheets)\n",
            "- <context id=\"2\" source=\"[Tesla 10-K, Note 2, p. 65]\"> (Cash and cash equivalents and restricted cash)\n",
            "- <context id=\"5\" source=\"[Tesla 10-K, Note 2, p. 65]\"> (Cash and cash equivalents and restricted cash)\n",
            "\n",
            "## Extract\n",
            "From <context id=\"1\" source=\"[Tesla 10-K, Item 8, p. 50]\">, we have:\n",
            "Cash and cash equivalents = $16,398 million (as of December 31, 2023)\n",
            "\n",
            "From <context id=\"2\" source=\"[Tesla 10-K, Note 2, p. 65]\">, we have:\n",
            "Cash and cash equivalents = $16,398 million (as of December 31, 2023)\n",
            "Restricted cash included in prepaid expenses and other current assets = Not specified\n",
            "Restricted cash included in other non-current assets = Not specified\n",
            "\n",
            "From <context id=\"5\" source=\"[Tesla 10-K, Note 2, p. 65]\">, we have:\n",
            "Total cash and cash equivalents and restricted cash = $17,189 million (as of December 31, 2023)\n",
            "\n",
            "## Synthesize\n",
            "We have two different values for cash and cash equivalents:\n",
            "- $16,398 million (from <context id=\"1\" source=\"[Tesla 10-K, Item 8, p. 50]\"> and <context id=\"2\" source=\"[Tesla 10-K, Note 2, p. 65]\">)\n",
            "- $17,189 million (from <context id=\"5\" source=\"[Tesla 10-K, Note 2, p. 65]\">)\n",
            "\n",
            "Since <context id=\"5\" source=\"[Tesla 10-K, Note 2, p. 65]\"> includes both cash and cash equivalents and restricted cash, we will use this value as the total cash and cash equivalents.\n",
            "\n",
            "## Calculate\n",
            "No calculation is needed, as the value is already provided.\n",
            "\n",
            "## Cite\n",
            "[\"Tesla 10-K\", \"Note 2\", \"p. 65\"]\n",
            "\n",
            "## Answer\n",
            "Tesla reported $17,189 million in total cash and cash equivalents and restricted cash as of December 31, 2023.\n",
            "\n",
            "ğŸ“š Sources: []\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test: Tesla cash\n",
        "ask(\"How much cash and cash equivalents did Tesla report?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b4e9402b",
      "metadata": {
        "id": "b4e9402b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â“ What will Apple's revenue be in 2025?\n",
            "------------------------------------------------------------\n",
            "ğŸ’¡ This question cannot be answered based on the provided documents.\n",
            "\n",
            "ğŸ“š Sources: []\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test: Out-of-scope (future prediction) - should refuse\n",
        "ask(\"What will Apple's revenue be in 2025?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "432899ee",
      "metadata": {
        "id": "432899ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â“ Should I invest in Tesla stock?\n",
            "------------------------------------------------------------\n",
            "ğŸ’¡ **Understand**: The user is asking for investment advice on Tesla stock.\n",
            "**Locate**: The context does not contain explicit investment advice or recommendations.\n",
            "**Extract**: The context mentions potential risks and challenges facing Tesla, such as:\n",
            "* Litigation and regulatory issues (contexts 5, 6, and 7)\n",
            "* Competition for key employees (context 4)\n",
            "* Potential impact of government incentives and tax credits (context 3)\n",
            "**Synthesize**: Based on the provided context, there is no explicit recommendation to invest in Tesla stock. The context highlights potential risks and challenges that may affect the company's performance.\n",
            "**Cite**: [\"Tesla 10-K\", \"Note 15\", \"p. 90\"], [\"Tesla 10-K\", \"Item 1A\", \"p. 21\"], [\"Tesla 10-K\", \"Item 1A\", \"p. 26\"]\n",
            "\n",
            "**Answer**: I cannot provide investment advice, stock recommendations, or trading guidance. The context does not contain explicit information about Tesla's stock performance or investment potential.\n",
            "\n",
            "ğŸ“š Sources: ['Tesla 10-K', 'Note 15', 'p. 90', 'Tesla 10-K', 'Item 1A', 'p. 21', 'Tesla 10-K', 'Item 1A', 'p. 26']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test: Out-of-scope (investment advice) - should refuse\n",
        "ask(\"Should I invest in Tesla stock?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e232fcae",
      "metadata": {
        "id": "e232fcae"
      },
      "source": [
        "## 6. Run Full Evaluation\n",
        "\n",
        "Test all 13 questions from the assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "37f29d83",
      "metadata": {
        "id": "37f29d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SEC 10-K RAG EVALUATION\n",
            "================================================================================\n",
            "\n",
            "Initializing pipeline...\n",
            "============================================================\n",
            "Initializing SEC 10-K RAG Pipeline\n",
            "============================================================\n",
            "\n",
            "[1/4] Loading embedding model...\n",
            "Using embedding model: bge-small\n",
            "  Model: BAAI/bge-small-en-v1.5\n",
            "  Dimensions: 384\n",
            "  Quality: good, Speed: fast\n",
            "  Device: mps\n",
            "Loading weights: 100%|â–ˆ| 199/199 [00:00<00:00, 4217.79it/s, Materializing param=\n",
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: BAAI/bge-small-en-v1.5\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | \u001b[38;5;208mUNEXPECTED\u001b[0m |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- \u001b[38;5;208mUNEXPECTED\u001b[0m\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "âœ“ Model loaded successfully\n",
            "\n",
            "[2/4] Loading reranker...\n",
            "Using reranker: ms-marco-mini\n",
            "  Model: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "  Quality: good, Speed: fast\n",
            "  Device: mps\n",
            "Loading weights: 100%|â–ˆ| 105/105 [00:00<00:00, 2331.37it/s, Materializing param=\n",
            "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "Key                          | Status     |  | \n",
            "-----------------------------+------------+--+-\n",
            "bert.embeddings.position_ids | \u001b[38;5;208mUNEXPECTED\u001b[0m |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- \u001b[38;5;208mUNEXPECTED\u001b[0m\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "âœ“ Reranker loaded\n",
            "\n",
            "[3/4] Initializing LLM...\n",
            "GroqLLM initialized with model: llama-3.1-8b-instant\n",
            "\n",
            "[4/4] Pipeline ready!\n",
            "  Hybrid search: True\n",
            "  Retrieval top-k: 15\n",
            "  Rerank top-k: 7\n",
            "============================================================\n",
            "Loading index from outputs/index...\n",
            "Loading vector store from outputs/index...\n",
            "VectorStore initialized\n",
            "  Dimension: 384\n",
            "  Hybrid search: True\n",
            "  Hybrid alpha: 0.7 (vector weight)\n",
            "âœ“ Loaded 491 chunks\n",
            "âœ“ Loaded 491 chunks\n",
            "Loaded existing index\n",
            "\n",
            "================================================================================\n",
            "RUNNING EVALUATION ON 13 QUESTIONS\n",
            "================================================================================\n",
            "\n",
            "[Q1] What was Apples total revenue for the fiscal year ended September 28, 2024?\n",
            "------------------------------------------------------------\n",
            "Answer: ## Understand\n",
            "The question is asking for Apple's total revenue for the fiscal year ended September 28, 2024.\n",
            "\n",
            "## Locate\n",
            "The relevant information is found in the Consolidated Statements of Operations in context id=\"1\".\n",
            "\n",
            "## Extract\n",
            "The total net sales for the fiscal year ended September 28, 2024, is $...\n",
            "Sources: ['Apple 10-K', 'Item 8', 'p. 32']\n",
            "\n",
            "[Q2] How many shares of common stock were issued and outstanding as of October 18, 2024?\n",
            "------------------------------------------------------------\n",
            "Answer: ## Understand\n",
            "The question is asking for the number of shares of common stock issued and outstanding as of October 18, 2024.\n",
            "\n",
            "## Locate\n",
            "The relevant information is found in context id=\"5\" and context id=\"6\".\n",
            "\n",
            "## Extract\n",
            "According to context id=\"5\", the number of shares of common stock issued and out...\n",
            "Sources: ['Apple 10-K', 'Part III', 'p. 2', 'Apple 10-K', 'Part III', 'p. 2']\n",
            "\n",
            "[Q3] What is the total amount of term debt (current + non-current) reported by Apple as of September 28, 2024?\n",
            "------------------------------------------------------------\n",
            "Answer: ## Understand\n",
            "The question asks for the total amount of term debt (current + non-current) reported by Apple as of September 28, 2024.\n",
            "\n",
            "## Locate\n",
            "The relevant information is found in the following context chunks:\n",
            "- <context id=\"1\" source=\"...\n",
            "Sources: ['Apple 10-K', 'Note 9', 'p. 46', 'Apple 10-K', 'Note 9', 'p. 46', 'Apple 10-K', 'Note 4', 'p. 41', 'Apple 10-K', 'Item 8', 'p. 34']\n",
            "\n",
            "[Q4] On what date was Apples 10-K report for 2024 signed and filed with the SEC?\n",
            "------------------------------------------------------------\n",
            "Answer: ## Understand\n",
            "The question asks for the date Apple's 10-K report for 2024 was signed and filed with the SEC.\n",
            "\n",
            "## Locate\n",
            "The relevant information is found in context chunk #2:...\n",
            "Sources: ['Apple 10-K', 'Item 10', 'p. 60', 'Apple 10-K', 'Item 10', 'p. 60']\n",
            "\n",
            "[Q5] Does Apple have any unresolved staff comments from the SEC as of this filing? How do you know?\n",
            "------------------------------------------------------------\n",
            "Answer: ## Understand\n",
            "The question is asking if Apple has any unresolved staff comments from the SEC as of the filing.\n",
            "\n",
            "## Locate\n",
            "The relevant context chunk is <context id=\"1\" source=\"...\n",
            "Sources: ['Apple 10-K', 'Item 1B', 'p. 20', 'Apple 10-K', 'Item 1B', 'p. 20']\n",
            "\n",
            "[Q6] What was Teslas total revenue for the year ended December 31, 2023?\n",
            "------------------------------------------------------------\n",
            "Answer: ## Understand\n",
            "The question asks for Tesla's total revenue for the year ended December 31, 2023.\n",
            "\n",
            "## Locate\n",
            "The relevant information is found in the Consolidated Statements of Operations (context id=\"1\").\n",
            "\n",
            "## Extract\n",
            "Total revenues for the year ended December 31, 2023, is $96,773 million. [\"Tesla 10-...\n",
            "Sources: ['Tesla 10-K', 'Item 8', 'p. 51', 'Tesla 10-K', 'Item 8', 'p. 51']\n",
            "\n",
            "[Q7] What percentage of Teslas total revenue in 2023 came from Automotive Sales (excluding Leasing)?\n",
            "------------------------------------------------------------\n",
            "Answer: ## Understand\n",
            "The question asks for the percentage of Tesla's total revenue in 2023 that came from Automotive Sales (excluding Leasing).\n",
            "\n",
            "## Locate\n",
            "The relevant information is found in context id=\"4\" and context id=\"2\".\n",
            "\n",
            "## Extract\n",
            "From context id=\"4\", we have:\n",
            "Automotive sales revenue = $78,509 mil...\n",
            "Sources: ['Tesla 10-K', 'Item 1', 'p. 39', 'Tesla 10-K', 'Item 8', 'p. 51']\n",
            "\n",
            "[Q8] What is the primary reason Tesla states for being highly dependent on Elon Musk?\n",
            "------------------------------------------------------------\n",
            "Answer: ## Understand\n",
            "The question asks about the primary reason Tesla states for being highly dependent on Elon Musk.\n",
            "\n",
            "## Locate\n",
            "The relevant information is found in context chunk \"1\" from the Tesla 10-K (FY2023).\n",
            "\n",
            "## Extract\n",
            "According to the document, Tesla is highly dependent on Elon Musk because he does...\n",
            "Sources: ['Tesla 10-K', 'Item 1A', 'p. 22']\n",
            "\n",
            "[Q9] What types of vehicles does Tesla currently produce and deliver?\n",
            "------------------------------------------------------------\n",
            "Answer: ## Understand\n",
            "The question asks about the types of vehicles Tesla currently produces and delivers.\n",
            "\n",
            "## Locate\n",
            "Relevant information is found in context chunk <context id=\"7\"> and <context id=\"1\">.\n",
            "\n",
            "## Extract\n",
            "From context chunk <context id=\"7\">:\n",
            "\"We currently manufacture five different consumer vehic...\n",
            "Sources: ['Tesla 10-K', 'Item 1', 'p. 5', 'Tesla 10-K', 'Item 1', 'p. 35', 'Tesla 10-K', 'Item 1', 'p. 5', 'Tesla 10-K', 'Item 1', 'p. 35']\n",
            "\n",
            "[Q10] What is the purpose of Teslas 'lease pass-through fund arrangements'?\n",
            "------------------------------------------------------------\n",
            "Answer: ## Understand\n",
            "The question is asking about the purpose of Tesla's \"lease pass-through fund arrangements\".\n",
            "\n",
            "## Locate\n",
            "The relevant information is found in context id=\"4\" and context id=\"5\".\n",
            "\n",
            "## Extract\n",
            "According to context id=\"4\", the lease pass-through fund arrangements are described as follows:\n",
            "\"Un...\n",
            "Sources: ['Tesla 10-K', 'Note 13', 'p. 82']\n",
            "\n",
            "[Q11] What is Teslas stock price forecast for 2025?\n",
            "------------------------------------------------------------\n",
            "Answer: This question cannot be answered based on the provided documents....\n",
            "Sources: []\n",
            "\n",
            "[Q12] Who is the CFO of Apple as of 2025?\n",
            "------------------------------------------------------------\n",
            "Answer: ## Understand\n",
            "The question asks for the Chief Financial Officer (CFO) of Apple as of 2025.\n",
            "\n",
            "## Locate\n",
            "The relevant context chunk is not explicitly mentioned in the provided context. However, we can infer that the CFO's information might be present in the context chunks related to the management or c...\n",
            "Sources: []\n",
            "\n",
            "[Q13] What color is Teslas headquarters painted?\n",
            "------------------------------------------------------------\n",
            "Answer: This question cannot be answered based on the provided documents....\n",
            "Sources: []\n",
            "\n",
            "================================================================================\n",
            "EVALUATION COMPLETE\n",
            "Results saved to: outputs/evaluation_results_20260130_202107.json\n",
            "================================================================================\n",
            "\n",
            "Output format:\n",
            "[\n",
            "  {\n",
            "    \"question_id\": 1,\n",
            "    \"answer\": \"## Understand\\nThe question is asking for Apple's total revenue for the fiscal year ended September 28, 2024.\\n\\n## Locate\\nThe relevant information is found in the Consolidated Statements of Operations in context id=\\\"1\\\".\\n\\n## Extract\\nThe total net sales for the fiscal year ended September 28, 2024, is $391,035 million.\\n\\n## Synthesize\\nThe total revenue for the fiscal year ended September 28, 2024, is $391,035 million.\\n\\n## Cite\\n[\\\"Apple 10-K\\\", \\\"Item 8\\\", \\\"p. 32\\\"]\\n\\nThe answer is $391,035 million.\",\n",
            "    \"sources\": [\n",
            "      \"Apple 10-K\",\n",
            "      \"Item 8\",\n",
            "      \"p. 32\"\n",
            "    ]\n",
            "  }\n",
            "]\n",
            "\n",
            "Summary:\n",
            "  Questions answered: 10\n",
            "  Questions refused/not found: 3\n"
          ]
        }
      ],
      "source": [
        "# Run the full evaluation script\n",
        "\n",
        "!python -m src.test.evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6c74f45",
      "metadata": {
        "id": "a6c74f45"
      },
      "source": [
        "## 7. Interactive Demo\n",
        "\n",
        "Ask your own questions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0fa2011",
      "metadata": {
        "id": "d0fa2011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â“ \n",
            "------------------------------------------------------------\n",
            "ğŸ’¡ Since there is no user question provided, I will demonstrate the response structure with a sample question.\n",
            "\n",
            "**Sample Question:** What are the production locations and statuses of Tesla's announced vehicle models in production and under development, as of the date of this Annual Report on Form 10-K?\n",
            "\n",
            "**Understand:** The question is asking for the production locations and statuses of Tesla's vehicle models.\n",
            "\n",
            "**Locate:** The relevant information is found in context chunk 6: [\"Tesla 10-K\", \"Item 1\", \"p. 35\"]\n",
            "\n",
            "**Extract:** The production locations and statuses of Tesla's announced vehicle models are listed as follows:\n",
            "\n",
            "1. Fremont Factory\n",
            "\t* Model S / Model X: Active\n",
            "\t* Model 3 / Model Y: Active\n",
            "2. Gigafactory Shanghai\n",
            "\t* Model 3 / Model Y: Active\n",
            "3. Gigafactory Berlin-Brandenburg\n",
            "\t* Model Y: Active\n",
            "4. Gigafactory Texas\n",
            "\t* Model Y: Active\n",
            "\n",
            "**Synthesize:** The production locations and statuses of Tesla's announced vehicle models in production and under development, as of the date of this Annual Report on Form 10-K, are listed above.\n",
            "\n",
            "**Cite:** [\"Tesla 10-K\", \"Item 1\", \"p. 35\"]\n",
            "\n",
            "Please note that this is a demonstration of the response structure, and the actual question will be answered based on the user's input.\n",
            "\n",
            "ğŸ“š Sources: ['Tesla 10-K', 'Item 1', 'p. 35', 'Tesla 10-K', 'Item 1', 'p. 35']\n",
            "\n",
            "â“ \n",
            "------------------------------------------------------------\n",
            "ğŸ’¡ Since there is no user question provided, I will demonstrate the response structure with a sample question.\n",
            "\n",
            "**Sample Question:** What are the production locations and statuses of Tesla's announced vehicle models in production and under development, as of the date of this Annual Report on Form 10-K?\n",
            "\n",
            "**Understand:** The question asks for the production locations and statuses of Tesla's vehicle models.\n",
            "\n",
            "**Locate:** The relevant information is found in context chunk 6: [\"Tesla 10-K\", \"Item 1\", \"p. 35\"].\n",
            "\n",
            "**Extract:** The production locations and statuses of Tesla's announced vehicle models are as follows:\n",
            "\n",
            "1. Fremont Factory\n",
            "\t* Model S / Model X: Active\n",
            "\t* Model 3 / Model Y: Active\n",
            "2. Gigafactory Shanghai\n",
            "\t* Model 3 / Model Y: Active\n",
            "3. Gigafactory Berlin-Brandenburg\n",
            "\t* Model Y: Active\n",
            "4. Gigafactory Texas\n",
            "\t* Model Y: Active\n",
            "\n",
            "**Synthesize:** The production locations and statuses of Tesla's announced vehicle models are listed above.\n",
            "\n",
            "**Cite:** [\"Tesla 10-K\", \"Item 1\", \"p. 35\"]\n",
            "\n",
            "Note: This is a demonstration of the response structure. Please provide a user question for a real response.\n",
            "\n",
            "ğŸ“š Sources: ['Tesla 10-K', 'Item 1', 'p. 35', 'Tesla 10-K', 'Item 1', 'p. 35']\n",
            "\n",
            "â“ \n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Interactive loop\n",
        "while True:\n",
        "    question = input(\"\\nğŸ” Enter your question (or 'quit' to exit): \")\n",
        "    if question.lower() in ['quit', 'exit', 'q']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    ask(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c3e3a1b",
      "metadata": {
        "id": "2c3e3a1b"
      },
      "source": [
        "---\n",
        "\n",
        "## System Architecture\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  PDF Parse  â”‚ â†’  â”‚  Chunk   â”‚ â†’  â”‚  Embed  â”‚ â†’  â”‚ FAISS+BM25 â”‚\n",
        "â”‚  (PyMuPDF)  â”‚    â”‚ (512 tok)â”‚    â”‚  (BGE)  â”‚    â”‚  (Hybrid)  â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                                        â”‚\n",
        "                                                        â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚   Answer    â”‚ â†  â”‚   LLM    â”‚ â†  â”‚ Rerank  â”‚ â†  â”‚   Search   â”‚\n",
        "â”‚ + Citations â”‚    â”‚  (Groq)  â”‚    â”‚(MS-MARCOâ”‚    â”‚  Results   â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "## Evaluation Results\n",
        "\n",
        "| Question | Status |\n",
        "|----------|--------|\n",
        "| Q1: Apple revenue | âœ… $391,035M |\n",
        "| Q2: Apple shares | âœ… 15,115,823,000 |\n",
        "| Q3: Apple term debt | âœ… $96,662M |\n",
        "| Q4: Apple 10-K date | âœ… November 1, 2024 |\n",
        "| Q5: SEC comments | âœ… Item 1B: None |\n",
        "| Q6: Tesla revenue | âœ… $96,773M |\n",
        "| Q7: Automotive % | âœ… 83.04% |\n",
        "| Q8: Elon dependency | âš ï¸ Valid interpretation |\n",
        "| Q9: Tesla vehicles | âœ… Model S, 3, X, Y |\n",
        "| Q10: Lease pass-through | âœ… Finance solar |\n",
        "| Q11-13: Out-of-scope | âœ… Correctly refused |\n",
        "\n",
        "**Overall: 12/13 correct (92.3%)**\n",
        "\n",
        "See `design_report.md` for detailed explanations of each design decision."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c4b21ad",
      "metadata": {
        "id": "5c4b21ad"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
