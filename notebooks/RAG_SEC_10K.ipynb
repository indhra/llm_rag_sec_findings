{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f09af7f7",
      "metadata": {
        "id": "f09af7f7"
      },
      "source": [
        "# SEC 10-K RAG System - Colab Demo\n",
        "\n",
        "**Author:** Indhra  \n",
        "**Assignment:** LLM + RAG Hands-On Coding Test\n",
        "\n",
        "This notebook demonstrates a RAG system for answering questions from Apple 2024 and Tesla 2023 10-K SEC filings.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/indhra/llm_rag_sec_findings/blob/main/notebooks/RAG_SEC_10K.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa74e5ee",
      "metadata": {
        "id": "fa74e5ee"
      },
      "source": [
        "## 1. Setup\n",
        "\n",
        "Clone the repository and install dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "75c1d526",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75c1d526",
        "outputId": "131d41df-4116-4666-b187-ca8f43ab9474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llm_rag_sec_findings'...\n",
            "remote: Enumerating objects: 147, done.\u001b[K\n",
            "remote: Counting objects: 100% (147/147), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 147 (delta 65), reused 135 (delta 53), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (147/147), 1.72 MiB | 7.12 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "/content/llm_rag_sec_findings/llm_rag_sec_findings/llm_rag_sec_findings\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/indhra/llm_rag_sec_findings.git\n",
        "%cd llm_rag_sec_findings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "21765355",
      "metadata": {
        "id": "21765355"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q pymupdf tiktoken sentence-transformers faiss-cpu rank-bm25 groq python-dotenv tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "eb06aced",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eb06aced",
        "outputId": "17d442ae-f662-4bf9-bb28-c6cbd867e552"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://console.groq.com/keys'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "\"https://console.groq.com/keys\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "a629a85a",
      "metadata": {
        "id": "a629a85a"
      },
      "outputs": [],
      "source": [
        "# Set your Groq API key (free at console.groq.com)\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Option 1: Enter manually\n",
        "# os.environ[\"GROQ_API_KEY\"] = getpass(\"Enter your Groq API key: \")\n",
        "\n",
        "# Option 2: Use Colab secrets (recommended)\n",
        "from google.colab import userdata\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('GROQ_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "f497f73c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f497f73c",
        "outputId": "1e4dcec5-536b-4a68-b058-27a84323e216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”‘ Validating Groq API key...\n",
            "âœ… API key is valid and working!\n",
            "   Model: llama-3.1-8b-instant\n",
            "   Response: How can I assist you\n"
          ]
        }
      ],
      "source": [
        "# Validate Groq API key\n",
        "print(\"ğŸ”‘ Validating Groq API key...\")\n",
        "try:\n",
        "    from groq import Groq\n",
        "\n",
        "    # Ensure the API key is stripped of any leading/trailing whitespace or newlines\n",
        "    groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "    if groq_api_key:\n",
        "        client = Groq(api_key=groq_api_key.strip())\n",
        "    else:\n",
        "        raise ValueError(\"GROQ_API_KEY environment variable is not set.\")\n",
        "\n",
        "    # Test with a simple request\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Hi\"}],\n",
        "        max_tokens=5\n",
        "    )\n",
        "\n",
        "    print(\"âœ… API key is valid and working!\")\n",
        "    print(f\"   Model: {response.model}\")\n",
        "    print(f\"   Response: {response.choices[0].message.content}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ API key validation failed: {str(e)}\")\n",
        "    print(\"\\nPlease check your API key and try again.\")\n",
        "    print(\"Get a free key at: https://console.groq.com/keys\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30cc5b1b",
      "metadata": {
        "id": "30cc5b1b"
      },
      "source": [
        "## 2. Download SEC 10-K PDFs\n",
        "\n",
        "Download Apple 2024 and Tesla 2023 10-K filings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "91e1196a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91e1196a",
        "outputId": "904f96b9-1e9f-4015-b99e-9493ff6faf71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using local copy\n",
            "Using local copy\n",
            "total 1916\n",
            "drwxr-xr-x 2 root root   4096 Jan 30 14:23 .\n",
            "drwxr-xr-x 8 root root   4096 Jan 30 14:23 ..\n",
            "-rw-r--r-- 1 root root 963934 Jan 30 14:23 10-Q4-2024-As-Filed.pdf\n",
            "-rw-r--r-- 1 root root      0 Jan 30 14:23 apple_10k_2024.pdf\n",
            "-rw-r--r-- 1 root root      0 Jan 30 14:23 tesla_10k_2023.pdf\n",
            "-rw-r--r-- 1 root root 984581 Jan 30 14:23 tsla-20231231-gen.pdf\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# Download Apple 10-K 2024\n",
        "!wget -q -O data/apple_10k_2024.pdf \"https://www.sec.gov/Archives/edgar/data/320193/000032019324000123/aapl-20240928.htm\" 2>/dev/null || echo \"Using local copy\"\n",
        "\n",
        "# Download Tesla 10-K 2023\n",
        "!wget -q -O data/tesla_10k_2023.pdf \"https://www.sec.gov/Archives/edgar/data/1318605/000162828024002390/tsla-20231231.htm\" 2>/dev/null || echo \"Using local copy\"\n",
        "\n",
        "# Check if files exist\n",
        "!ls -la data/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99bf36ca",
      "metadata": {
        "id": "99bf36ca"
      },
      "source": [
        "## 3. Initialize RAG Pipeline\n",
        "\n",
        "Load the embedding model, reranker, and LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0bc89bc1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bc89bc1",
        "outputId": "6da7e4fd-221e-40a4-e3b5-b2918d15eaab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Initializing SEC 10-K RAG Pipeline\n",
            "============================================================\n",
            "\n",
            "[1/4] Loading embedding model...\n",
            "Using embedding model: bge-small\n",
            "  Model: BAAI/bge-small-en-v1.5\n",
            "  Dimensions: 384\n",
            "  Quality: good, Speed: fast\n",
            "  Device: cpu\n",
            "âœ“ Model loaded successfully\n",
            "\n",
            "[2/4] Loading reranker...\n",
            "Using reranker: ms-marco-mini\n",
            "  Model: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "  Quality: good, Speed: fast\n",
            "  Device: cpu\n",
            "âœ“ Reranker loaded\n",
            "\n",
            "[3/4] Initializing LLM...\n",
            "GroqLLM initialized with model: llama-3.1-8b-instant\n",
            "\n",
            "[4/4] Pipeline ready!\n",
            "  Hybrid search: True\n",
            "  Retrieval top-k: 15\n",
            "  Rerank top-k: 7\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "from src.pipeline import RAGPipeline\n",
        "\n",
        "# Initialize with Groq (free tier)\n",
        "pipeline = RAGPipeline(\n",
        "    embedding_model=\"bge-small\",    # Fast, good quality\n",
        "    reranker_model=\"ms-marco-mini\", # Fast cross-encoder\n",
        "    llm_provider=\"groq\",            # Free API\n",
        "    use_hybrid_search=True,         # Vector + BM25\n",
        "    top_k_retrieval=15,             # Initial candidates (increased for better coverage)\n",
        "    top_k_rerank=7                  # After reranking (increased for complex questions)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd0a14cb",
      "metadata": {
        "id": "fd0a14cb"
      },
      "source": [
        "## 4. Index Documents\n",
        "\n",
        "Parse PDFs, chunk, embed, and build the vector index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0f30e1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0f30e1a",
        "outputId": "7a28681d-d15d-4dde-9760-fa7c5d043741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Indexing SEC 10-K Documents\n",
            "============================================================\n",
            "\n",
            "[Step 1] Parsing PDFs...\n",
            "Parsing 'Apple 10-K' (121 pages)...\n",
            "âœ“ Parsed 121 pages from Apple 10-K\n",
            "Parsing 'Tesla 10-K' (130 pages)...\n",
            "âœ“ Parsed 130 pages from Tesla 10-K\n",
            "\n",
            "[Step 2] Chunking documents...\n",
            "Chunking Apple 10-K...\n"
          ]
        }
      ],
      "source": [
        "# This takes ~2 minutes on Colab (mostly embedding generation)\n",
        "num_chunks = pipeline.index_documents(data_dir=\"data/\")\n",
        "print(f\"\\nâœ… Indexed {num_chunks} chunks!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fd07191",
      "metadata": {
        "id": "8fd07191"
      },
      "source": [
        "## 5. Ask Questions!\n",
        "\n",
        "Now we can ask questions about the 10-K filings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83915419",
      "metadata": {
        "id": "83915419"
      },
      "outputs": [],
      "source": [
        "def ask(question: str):\n",
        "    \"\"\"Helper function to ask a question and display the answer.\"\"\"\n",
        "    print(f\"â“ {question}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    result = pipeline.answer_question(question)\n",
        "\n",
        "    print(f\"ğŸ’¡ {result['answer']}\")\n",
        "    print(f\"\\nğŸ“š Sources: {result['sources']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81bd95c0",
      "metadata": {
        "id": "81bd95c0"
      },
      "outputs": [],
      "source": [
        "# Test: Apple revenue\n",
        "ask(\"What was Apple's total revenue for fiscal year 2024?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "671dfe40",
      "metadata": {
        "id": "671dfe40"
      },
      "outputs": [],
      "source": [
        "# Test: Tesla net income\n",
        "ask(\"What was Tesla's net income for fiscal year 2023?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb3f052",
      "metadata": {
        "id": "fdb3f052"
      },
      "outputs": [],
      "source": [
        "# Test: Apple R&D\n",
        "ask(\"How much did Apple spend on research and development in 2024?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41f2876d",
      "metadata": {
        "id": "41f2876d"
      },
      "outputs": [],
      "source": [
        "# Test: Tesla cash\n",
        "ask(\"How much cash and cash equivalents did Tesla report?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e9402b",
      "metadata": {
        "id": "b4e9402b"
      },
      "outputs": [],
      "source": [
        "# Test: Out-of-scope (future prediction) - should refuse\n",
        "ask(\"What will Apple's revenue be in 2025?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "432899ee",
      "metadata": {
        "id": "432899ee"
      },
      "outputs": [],
      "source": [
        "# Test: Out-of-scope (investment advice) - should refuse\n",
        "ask(\"Should I invest in Tesla stock?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e232fcae",
      "metadata": {
        "id": "e232fcae"
      },
      "source": [
        "## 6. Run Full Evaluation\n",
        "\n",
        "Test all 13 questions from the assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f29d83",
      "metadata": {
        "id": "37f29d83"
      },
      "outputs": [],
      "source": [
        "# Run the full evaluation script\n",
        "\n",
        "!python -m src.test.evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6c74f45",
      "metadata": {
        "id": "a6c74f45"
      },
      "source": [
        "## 7. Interactive Demo\n",
        "\n",
        "Ask your own questions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0fa2011",
      "metadata": {
        "id": "d0fa2011"
      },
      "outputs": [],
      "source": [
        "# Interactive loop\n",
        "while True:\n",
        "    question = input(\"\\nğŸ” Enter your question (or 'quit' to exit): \")\n",
        "    if question.lower() in ['quit', 'exit', 'q']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    ask(question)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c3e3a1b",
      "metadata": {
        "id": "2c3e3a1b"
      },
      "source": [
        "---\n",
        "\n",
        "## System Architecture\n",
        "\n",
        "```\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  PDF Parse  â”‚ â†’  â”‚  Chunk   â”‚ â†’  â”‚  Embed  â”‚ â†’  â”‚ FAISS+BM25 â”‚\n",
        "â”‚  (PyMuPDF)  â”‚    â”‚ (512 tok)â”‚    â”‚  (BGE)  â”‚    â”‚  (Hybrid)  â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "                                                        â”‚\n",
        "                                                        â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚   Answer    â”‚ â†  â”‚   LLM    â”‚ â†  â”‚ Rerank  â”‚ â†  â”‚   Search   â”‚\n",
        "â”‚ + Citations â”‚    â”‚  (Groq)  â”‚    â”‚(MS-MARCOâ”‚    â”‚  Results   â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "## Evaluation Results\n",
        "\n",
        "| Question | Status |\n",
        "|----------|--------|\n",
        "| Q1: Apple revenue | âœ… $391,035M |\n",
        "| Q2: Apple shares | âœ… 15,115,823,000 |\n",
        "| Q3: Apple term debt | âœ… $96,662M |\n",
        "| Q4: Apple 10-K date | âœ… November 1, 2024 |\n",
        "| Q5: SEC comments | âœ… Item 1B: None |\n",
        "| Q6: Tesla revenue | âœ… $96,773M |\n",
        "| Q7: Automotive % | âœ… 83.04% |\n",
        "| Q8: Elon dependency | âš ï¸ Valid interpretation |\n",
        "| Q9: Tesla vehicles | âœ… Model S, 3, X, Y |\n",
        "| Q10: Lease pass-through | âœ… Finance solar |\n",
        "| Q11-13: Out-of-scope | âœ… Correctly refused |\n",
        "\n",
        "**Overall: 12/13 correct (92.3%)**\n",
        "\n",
        "See `design_report.md` for detailed explanations of each design decision."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c4b21ad",
      "metadata": {
        "id": "5c4b21ad"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}